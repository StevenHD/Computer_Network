# 第14讲 | HTTP协议：看个新闻原来这么麻烦

前面讲述完传输层，接下来开始讲**应用层**的协议。

https://www.163.com/是个 URL，叫作统一资源定位符。之所以叫统一，是因为它是有格式的。

HTTP 称为协议。

www.163.com 是一个域名，表示互联网上的一个位置。

因为这个东西是统一的，所以当你把这样一个字符串输入到浏览器的框里的时候，浏览器才知道如何进行统一处理。

---

###HTTP 请求的准备

浏览器会将 www.163.com 这个域名发送给 DNS 服务器，让它解析为 IP 地址。

被解析成为 IP 地址后，那接下来是发送 HTTP 请求吗？

不是的，HTTP 是基于 TCP 协议的，当然是要先建立 TCP 连接了，怎么建立呢？

目前使用的 HTTP 协议大部分都是 1.1。**在 1.1 的协议**里面，默认是**开启了 Keep-Alive** 的，这样建立的 TCP 连接，就可以**在多次请求中复用**。

---

### HTTP 请求的构建

**建立了连接**以后，浏览器就要**发送 HTTP 的请求。**

HTTP 的报文大概分为三大部分。

第一部分是请求行，

第二部分是请求的首部，

第三部分才是请求的正文实体。

---

### 第一部分：请求行

在请求行中，URL 就是 http://www.163.com ，版本为 HTTP 1.1。这里要说一下的，就是方法。

对于访问网页来讲，最常用的类型就是 **GET**。

GET 就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。

> 例如，在云计算中，如果我们的服务器端要提供一个基于 HTTP 协议的 API，获取所有云主机的列表，这就会使用 GET 方法得到，返回的可能是一个 JSON 字符串。字符串里面是一个列表，列表里面是一项的云主机的信息。

另外一种类型叫做 POST。它需要**主动告诉服务端一些信息**，而**非获取**。

要告诉服务端什么呢？一般会放在正文里面。正文可以有各种各样的格式。常见的格式也是 JSON。

> 例如，我们下一节要讲的支付场景，客户端就需要把“我是谁？我要支付多少？我要买啥？”告诉服务器，这就需要通过 POST 方法。

> 再如，在云计算里，如果我们的服务器端，要提供一个基于 HTTP 协议的创建云主机的 API，也会用到 POST 方法。这个时候往往需要将“我要创建多大的云主机？多少 CPU 多少内存？多大硬盘？”这些信息放在 JSON 字符串里面，通过 POST 的方法告诉服务器端。

POST 往往是用来创建一个资源的，而 PUT 往往是用来修改一个资源的。

> 例如，云主机已经创建好了，我想对这个云主机打一个标签，说明这个云主机是生产环境的，另外一个云主机是测试环境的。那怎么修改这个标签呢？往往就是用 PUT 方法。

再有一种常见的就是 DELETE。这个顾名思义就是用来删除资源的。

> 例如，我们要删除一个云主机，就会调用 DELETE 方法。

---

### 第二部分：首部字段

首部是 key value，通过冒号分隔。这里面，往往保存了一些**非常重要的字段**。

> 例如，Accept-Charset，表示客户端可以接受的字符集。防止传过来的是另外的字符集，从而导致出现乱码。



> 再如，Content-Type 是指正文的格式。例如，我们进行 POST 的请求，如果正文是 JSON，那么我们就应该将这个值设置为 JSON。

需要重点说一下的就是**缓存**。为啥要使用缓存呢？那是因为一个非常大的页面有很多东西。

> 例如，我浏览一个商品的详情，里面有这个商品的价格、库存、展示图片、使用手册等等。商品的展示图片会保持较长时间不变，而库存会根据用户购买的情况经常改变。如果图片非常大，而库存数非常小，如果我们每次要更新数据的时候都要刷新整个页面，对于服务器的压力就会很大。

**对于这种高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面**。

这个架构的图就像这样。

![img](https://static001.geekbang.org/resource/image/c8/ac/c81af7a52305f7de27e32e34a02d0eac.jpg)

和这一节关系比较大的就是 **Nginx 这一层**，它如何处理 HTTP 协议呢？对于静态资源，有 Vanish 缓存层。当缓存过期的时候，才会访问真正的 Tomcat 应用集群。

在 HTTP 头里面，Cache-control 是用来控制缓存的。

另外，If-Modified-Since 也是一个关于缓存的。

到此为止，我们仅仅是拼凑起了 HTTP 请求的报文格式，

接下来，浏览器会把它交给下一层传输层。

怎么交给传输层呢？其实也无非是用 Socket 这些东西，

只不过用的浏览器里，这些程序不需要你自己写，有人已经帮你写好了。

---

#### HTTP 请求的发送

HTTP 协议是基于 TCP 协议的，所以它使用面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。当然，到了 TCP 层，它会把二进制流变成一个个报文段发送给服务器。

在发送给每个报文段的时候，都需要对方有一个回应 ACK，来保证报文可靠地到达了对方。

TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。

IP 层需要查看目标地址和自己是否是在同一个局域网。

如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；

如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来**获取网关的 MAC 地址**，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。

网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。

这样路由器一跳一跳终于到达目标的局域网。

这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。

**目标的机器**发现 MAC 地址符合，就将包收起来；

发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。

TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。

---

### HTTP 返回的构建

HTTP 的返回报文也是有一定格式的。这也是基于 HTTP 1.1 的。

态码会反映 HTTP 请求的结果。“200”意味着大吉大利；而我们最不想见的，就是“404”，也就是“服务端无法响应这个请求”。

接下来是返回**首部的 key value**。这里面，**Retry-After 表示**，告诉客户端应该在多长时间以后再次尝试一下。

**“503 错误”是说“服务暂时不再和这个值配合使用**”。

在返回的头部里面也会有 **Content-Type**，表示返回的是 HTML，还是 JSON。

构造好了返回的 HTTP 报文，接下来就是把这个报文发送出去。

这些段加上 TCP 头后会交给 IP 层，然后把刚才的发送过程反向走一遍。

客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。

这个进程就是浏览器，浏览器作为客户端也在监听某个端口。

**这就是一个正常的 HTTP 请求和返回的完整过程**。

---

HTTP 1.1 在应用层以纯文本的形式进行通信。

HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key value 在两端建立一个索引表，对相同的头只发送索引表中的索引。

HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。

> HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有 **Header 帧**，用于传输 Header 内容，并且会开启一个新的流。再就是 **Data 帧**，用来传输正文实体。多个 Data 帧属于同一个流。

HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应；减少了 TCP 连接数对服务器性能的影响，同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。

---

HTTP 2.0 虽然大大**增加了并发性**，但还是有问题的。因为 **HTTP 2.0 也是基于 TCP 协议的**，**TCP 协议在处理包时是有严格顺序**的。

当其中一个数据包遇到问题，TCP 连接需要**等待这个包完成重传之后**才能继续进行。

又到了从 TCP 切换到 UDP，进行“城会玩”的时候了。这就是 **Google 的 QUIC 协议**，接下来我们来看它是如何“城会玩”的。

---

### 机制一：自定义连接机制

我们都知道，一条 TCP 连接是由四元组标识的，分别是源 IP、源端口、目的 IP、目的端口。

但是基于 UDP，就可以在 QUIC 自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化的时候，只要 ID 不变，就**不需要重新建立连接**。

---

### 机制二：自定义重传机制

TCP 为了保证可靠性，通过**使用序号和应答机制**，来解决**顺序问题和丢包问题**。

> 那怎么样才算超时呢？还记得我们提过的**自适应重传算法**吗？这个超时是通过**采样往返时间 RTT** 不断调整的。

其实，在 TCP 里面超时的采样存在不准确的问题。

QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。

> 例如，发送一个包，序号是 100，发现没有返回；再次发送的时候，序号就是 101 了；如果返回的 ACK 100，就是对第一个包的响应。如果返回 ACK 101 就是对第二个包的响应，RTT 计算相对准确。

但是这里有一个问题，就是怎么知道包 100 和包 101 发送的是同样的内容呢？

QUIC 定义了**一个 offset 概念**。

**QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流，发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里**，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。

---

### 机制三：无阻塞的多路复用

有了**自定义的连接和重传机制**，我们就可以解决上面 **HTTP 2.0 的多路复用问题**。

QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。

> 假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。

---

### 机制四：自定义流量控制

TCP 的流量控制是通过**滑动窗口协议**。QUIC 的流量控制也是通过 window_update，来告诉对端它可以接受的字节数。

但是 QUIC 的窗口是适应自己的多路复用机制的，不但在一个连接上控制窗口，**还在一个连接中的每个 stream 控制窗口**。

另外，还有**整个连接的窗口，需要对于所有的 stream 的窗口做一个统计**。

---

**小结**

- HTTP 协议虽然很常用，也很复杂，重点记住 GET、POST、 PUT、DELETE 这几个方法，以及重要的首部字段；
- HTTP 2.0 通过头压缩、分帧、二进制编码、多路复用等技术提升性能；
- QUIC 协议通过基于 UDP 自定义的类似 TCP 的连接、重试、多路复用、流量控制技术，进一步提升性能。